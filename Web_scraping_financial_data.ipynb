{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Planejamento do projeto\n",
    "\n",
    "## Resultado final\n",
    "    - Uma classe em linguagem python em que o usuário digita o símbolo da ação (stock ticker) e recebe uma série \n",
    "    de gráficos e análises da empresa selecionada.\n",
    "    - Quais análises serão entregues?\n",
    "        . Gráfico interativo com o comportamento das ações no tempo;\n",
    "        . Relatório com os principais indicadores;\n",
    "        . Avaliação de investimento, favorável ou desvaforável?\n",
    "        . Previsão de comportamento?\n",
    "\n",
    "## Ferramental\n",
    "    - Utilizar o Jupyter Notebook para a escrita e interpretação do código;\n",
    "    - Utilizar a biblioteca Selenium ou urllib.request para analisar conteudos de páginas;\n",
    "    - Utilizar a biblioteca Beautiful Soup (ou lXml e Scrapy) que torna possível ler o conteúdo das páginas HTML;\n",
    "    - Utilizar a biblioteca Pandas para armazenar o conteúdo das páginas em DataFrames;\n",
    "    - Utilizar a biblioteca Numpy para realização de operações;\n",
    "    - Utilizar a biblioteca Plotly para desenhar gráficos interativos;\n",
    "    - Utilizar a biblioetca pyplot da matplotlib para criação de gráficos e dashboards;\n",
    "    - Utilizar a biblioteca sklearn para a adaptação de um modelo de previsão de preço de ação.\n",
    "    \n",
    "## Processo de desenvolvimento\n",
    "    - Coletar os dados das páginas que contêm informações sobre ações: https://finance.yahoo.com/ \n",
    "        - Dados históricos dos preços das ações\n",
    "        - Indicadores fundamentalistas das ações \n",
    "        - Dados históricos dos fundos \n",
    "        - Indicadores dos fundos\n",
    "    - Organizar os dados em DataFrames\n",
    "    - Tratar os dados, isto é, retirar dados duplicados, tratar dados faltantes, ajustar indices e headers\n",
    "    - Gerar as análises dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilizando o URLLIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports para o desenvolvimento do projeto\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as ur\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Endereço de uma das páginas a qual fornecerá informações para a análise\n",
    "url = \"https://br.financas.yahoo.com/quote/{}/history?period1={}&period2={}&interval=1d&filter=history&frequency=1d&includeAdjustedClose=true\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratar condições de erro\n",
    "\n",
    "## Como tratar possíveis condições de erro? \n",
    "    - Colocando try except \n",
    "    - Colocando assert\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inserir o nome empresa\n",
    "ticker = input()\n",
    "\n",
    "# Selecionado a data do horizonte de busca de 5 anos \n",
    "date2 = np.timedelta64(np.datetime64('today') - np.datetime64('1969-12-31'), 's').astype(int)\n",
    "date1 = date2 - 86400 * 365 * 5\n",
    "\n",
    "# Formatando o url \n",
    "url = url.format(ticker, date1, date2)\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionar cabeçalho para passar informações adicionais. Deve-se identificar o erro retornado pelo navegador (401 por exemplo\n",
    "# é um exemplo de permissão negada) e adicionar o cabeçalho correspondente, no caso o site necessitava de alguma identificação \n",
    "# para concretizar a requisição, essa informação pode ser o tipo de aplicação o sistema operacional, fornecedores, a versão \n",
    "# de agente de usuário requisitante e outros. \"Mozilla/5.0\" é o token geral que diz que o navegador é compatível com Mozilla.\n",
    "# Por razões históricas, quase todo navegador envia isso hoje. \n",
    "# Fonte: https://developer.mozilla.org/pt-BR/docs/Web/HTTP/Headers/User-Agent\n",
    "     \n",
    "response = requests.get(url, headers=headers) #baixa o conteúdo de uma página na web\n",
    "status = response.raise_for_status()\n",
    "\n",
    "# Retorna um objeto BeautifulSoup que permite manipular o data structure com mais facilidade\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# O título da página HTML\n",
    "print(soup.title.string)\n",
    "\n",
    "linhas = [] #lista para armazenar os dados retirados do HTML\n",
    "for element in soup.find_all(['th', 'td', 'strong']):\n",
    "    linhas.append(element.string) #retira os strings que acompanham as classes selecionadas\n",
    "    \n",
    "# Tratando os strings para obter o dado desejado\n",
    "linhas = [e for e in linhas if e not in ('Operating Expenses','Non-recurring Events')]\n",
    "new_lista = list(filter(None,linhas)) #retira os Nones\n",
    "\n",
    "dado = list(zip(*[iter(new_lista)]*7))\n",
    "df_dado = pd.DataFrame(dado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raspagem da tabela de preços de ações utilizando o Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd \n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last_height: 583\n",
      "new_height: 8316\n",
      "new_height: 12105\n",
      "new_height: 15894\n",
      "new_height: 16018\n",
      "new_height: 16018\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_Time</th>\n",
       "      <th>Data</th>\n",
       "      <th>Abrir</th>\n",
       "      <th>Alto</th>\n",
       "      <th>Baixo</th>\n",
       "      <th>Fechamento*</th>\n",
       "      <th>Fechamento ajustado**</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-20</th>\n",
       "      <td>2022-01-20</td>\n",
       "      <td>20 de jan. de 2022</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.10</td>\n",
       "      <td>100.10</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-19</th>\n",
       "      <td>2022-01-19</td>\n",
       "      <td>19 de jan. de 2022</td>\n",
       "      <td>101.00</td>\n",
       "      <td>101.99</td>\n",
       "      <td>100.18</td>\n",
       "      <td>101.80</td>\n",
       "      <td>101.80</td>\n",
       "      <td>60057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-18</th>\n",
       "      <td>2022-01-18</td>\n",
       "      <td>18 de jan. de 2022</td>\n",
       "      <td>99.37</td>\n",
       "      <td>100.85</td>\n",
       "      <td>99.04</td>\n",
       "      <td>100.85</td>\n",
       "      <td>100.85</td>\n",
       "      <td>41217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-17</th>\n",
       "      <td>2022-01-17</td>\n",
       "      <td>17 de jan. de 2022</td>\n",
       "      <td>97.79</td>\n",
       "      <td>99.90</td>\n",
       "      <td>97.33</td>\n",
       "      <td>99.37</td>\n",
       "      <td>99.37</td>\n",
       "      <td>41972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-14</th>\n",
       "      <td>2022-01-14</td>\n",
       "      <td>14 de jan. de 2022</td>\n",
       "      <td>97.20</td>\n",
       "      <td>97.90</td>\n",
       "      <td>96.84</td>\n",
       "      <td>97.80</td>\n",
       "      <td>97.80</td>\n",
       "      <td>63940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-10</th>\n",
       "      <td>2020-06-10</td>\n",
       "      <td>10 de jun. de 2020</td>\n",
       "      <td>119.06</td>\n",
       "      <td>121.95</td>\n",
       "      <td>118.97</td>\n",
       "      <td>120.81</td>\n",
       "      <td>120.81</td>\n",
       "      <td>65441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-09</th>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>09 de jun. de 2020</td>\n",
       "      <td>118.49</td>\n",
       "      <td>118.97</td>\n",
       "      <td>117.00</td>\n",
       "      <td>118.97</td>\n",
       "      <td>118.97</td>\n",
       "      <td>93157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-08</th>\n",
       "      <td>2020-06-08</td>\n",
       "      <td>08 de jun. de 2020</td>\n",
       "      <td>117.36</td>\n",
       "      <td>119.00</td>\n",
       "      <td>117.21</td>\n",
       "      <td>118.50</td>\n",
       "      <td>118.50</td>\n",
       "      <td>125987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-05</th>\n",
       "      <td>2020-06-05</td>\n",
       "      <td>05 de jun. de 2020</td>\n",
       "      <td>115.75</td>\n",
       "      <td>117.87</td>\n",
       "      <td>115.75</td>\n",
       "      <td>117.36</td>\n",
       "      <td>117.36</td>\n",
       "      <td>75750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-04</th>\n",
       "      <td>2020-06-04</td>\n",
       "      <td>04 de jun. de 2020</td>\n",
       "      <td>115.89</td>\n",
       "      <td>116.94</td>\n",
       "      <td>115.10</td>\n",
       "      <td>115.61</td>\n",
       "      <td>115.61</td>\n",
       "      <td>104587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Data_Time                Data   Abrir    Alto   Baixo  \\\n",
       "Data_Time                                                           \n",
       "2022-01-20 2022-01-20  20 de jan. de 2022    0.00    0.00    0.00   \n",
       "2022-01-19 2022-01-19  19 de jan. de 2022  101.00  101.99  100.18   \n",
       "2022-01-18 2022-01-18  18 de jan. de 2022   99.37  100.85   99.04   \n",
       "2022-01-17 2022-01-17  17 de jan. de 2022   97.79   99.90   97.33   \n",
       "2022-01-14 2022-01-14  14 de jan. de 2022   97.20   97.90   96.84   \n",
       "...               ...                 ...     ...     ...     ...   \n",
       "2020-06-10 2020-06-10  10 de jun. de 2020  119.06  121.95  118.97   \n",
       "2020-06-09 2020-06-09  09 de jun. de 2020  118.49  118.97  117.00   \n",
       "2020-06-08 2020-06-08  08 de jun. de 2020  117.36  119.00  117.21   \n",
       "2020-06-05 2020-06-05  05 de jun. de 2020  115.75  117.87  115.75   \n",
       "2020-06-04 2020-06-04  04 de jun. de 2020  115.89  116.94  115.10   \n",
       "\n",
       "            Fechamento*  Fechamento ajustado**  Volume  \n",
       "Data_Time                                               \n",
       "2022-01-20       100.10                 100.10       -  \n",
       "2022-01-19       101.80                 101.80   60057  \n",
       "2022-01-18       100.85                 100.85   41217  \n",
       "2022-01-17        99.37                  99.37   41972  \n",
       "2022-01-14        97.80                  97.80   63940  \n",
       "...                 ...                    ...     ...  \n",
       "2020-06-10       120.81                 120.81   65441  \n",
       "2020-06-09       118.97                 118.97   93157  \n",
       "2020-06-08       118.50                 118.50  125987  \n",
       "2020-06-05       117.36                 117.36   75750  \n",
       "2020-06-04       115.61                 115.61  104587  \n",
       "\n",
       "[404 rows x 8 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ajuste do url\n",
    "# inserir o nome empresa\n",
    "ticker = \"XPLG11.SA\"\n",
    "\n",
    "# selecionado a data do horizonte de busca de 5 anos \n",
    "date2 = np.timedelta64(np.datetime64('today') - np.datetime64('1969-12-31'), 's').astype(int)\n",
    "date1 = date2 - 86400 * 365 * 5\n",
    "\n",
    "url = \"https://br.financas.yahoo.com/quote/{}/history?period1={}&period2={}&interval=1d&filter=history&frequency=1d&includeAdjustedClose=true\"\n",
    "\n",
    "# formatando o url da página que será acessada\n",
    "url = url.format(ticker, date1, date2)\n",
    "\n",
    "# Instância do navegador\n",
    "opt = webdriver.ChromeOptions()\n",
    "opt.headless = True #não mostrar a ação em andamento \n",
    "ser = Service(r'C:\\Program Files (x86)\\Google\\Chrome\\Application\\97.0.4692.99\\chromedriver.exe')\n",
    "driver = webdriver.Chrome(service=ser, options=opt)\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "html = driver.find_element(By.TAG_NAME, 'html')\n",
    "\n",
    "# posição do inicial do scroll\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "print(\"last_height: {}\".format(last_height))\n",
    "\n",
    "while (True):\n",
    "    # posiciona o scroll no final da página\n",
    "    html.send_keys(Keys.END)\n",
    "    \n",
    "    # pausa para carregar a página\n",
    "    time.sleep(1)\n",
    "\n",
    "    # atualiza a posição do scroll \n",
    "    new_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "    print(\"new_height: {}\".format(new_height))\n",
    "    \n",
    "    # verifica se houve movimento da página \n",
    "    if (new_height == last_height):\n",
    "        # termina o loop\n",
    "        break\n",
    "    else:\n",
    "        # atualiza o último valor \n",
    "        last_height = new_height         \n",
    "\n",
    "element = driver.find_element(By.TAG_NAME, 'table')\n",
    "html_content = element.get_attribute('outerHTML')\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# Código HTML da tabela\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Tratando o HTML para gerar a tabela de hostórico do preço da ação\n",
    "# lista para armazenar o dados que não sejam relacionados com o preço da ação (dividendo e desdobramento)\n",
    "list_not_related = [] #lista com conteúdo não relacionado com o preço das ações\n",
    "tuplas_eventos = [] #tuplas data, valor, ocorrencia (dividendo e desdobramento)\n",
    "for element in soup.find_all('td',\"Ta(start) Py(10px)\"):\n",
    "    list_not_related.append(element)\n",
    "    tuplas_eventos.append((element.previous_element, element.find('strong').string, element.find('span').string))\n",
    "\n",
    "linhas_tab = [] #lista para armazenar os dados das linhas da tebela\n",
    "# retira os strings que acompanham as classes selecionadas e filtra os casos não queridos\n",
    "for element in soup.find_all(['td', 'th']):\n",
    "    if element in list_not_related:\n",
    "        del(linhas_tab[-1]) #deleta o elemento anterior\n",
    "    else:\n",
    "        linhas_tab.append(element.string)\n",
    "        \n",
    "new_lista = list(filter(None, linhas_tab)) #retira os Nones se existirem\n",
    "stock_data = list(zip(*[iter(new_lista)]*7)) #empacota em listas de 7 elementos \n",
    "\n",
    "df_data_stocks = pd.DataFrame(stock_data[1:], columns=stock_data[0][0:7]) \n",
    "df_not_related = pd.DataFrame(tuplas_eventos, columns=['Data', 'Valor', 'Tipo'])\n",
    "\n",
    "\n",
    "# Tratando o DataFrame\n",
    "# converte a última coluna para inteiro substituindo o ponto\n",
    "df_data_stocks[\"Volume\"] = df_data_stocks['Volume'].apply(lambda x: int(x.replace(\".\",\"\")) if x != \"-\" else x)\n",
    "\n",
    "# laço para substituir os pontos por vírgulas \n",
    "for coluna in df_data_stocks.columns[1:6]:\n",
    "    df_data_stocks[coluna] = df_data_stocks[coluna].apply(lambda x: float(x.replace(\",\",\".\")) if x != '-' else x)\n",
    "\n",
    "# dicionário para auxiliar na correção das datas\n",
    "dicio = {\"jan.\": \"01\",\n",
    "         \"fev.\": \"02\",\n",
    "         \"mar.\": \"03\",\n",
    "         \"abr.\": \"04\",\n",
    "         \"mai.\": \"05\",\n",
    "         \"jun.\": \"06\",\n",
    "         \"jul.\": \"07\",\n",
    "         \"ago.\": \"08\",\n",
    "         \"set.\": \"09\",\n",
    "         \"out.\": \"10\",\n",
    "         \"nov.\": \"11\",\n",
    "         \"dez.\": \"12\"}\n",
    "\n",
    "# ordenando cada data por Ano-mês-dia, substituindo o nome do mês pelo número correspondente e convertendo para datetime64\n",
    "df_data_stocks[\"Data_Time\"] = pd.to_datetime(df_data_stocks[\"Data\"].apply(lambda x: x.split(' ')[0:6:2][::-1]).\\\n",
    "                                             apply(lambda x: \"\".join([x[0], dicio[x[1]], x[2]])), \n",
    "                                             format='%Y-%m-%d')\n",
    "\n",
    "# Rearanjando as colunas do dataframe\n",
    "cols = df_data_stocks.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "df_data_stocks = df_data_stocks[cols]\n",
    "df_data_stocks.index = df_data_stocks['Data_Time'] #faz o índice virar a coluna data_time\n",
    "df_data_stocks.drop(labels='Data_Time', axis=1)\n",
    "\n",
    "df_data_stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabela de indicadores de FII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.fundsexplorer.com.br/ranking'\n",
    "header ={'user-agent':'Mozilla/5.0'}\n",
    "lendo_url = requests.get(url, headers = header)\n",
    "\n",
    "lendo_url2 = lendo_url.text\n",
    "# lendo_url2\n",
    "soup = BeautifulSoup(lendo_url.content,'html.parser')\n",
    "listona = []\n",
    "\n",
    "for i in soup.find_all('td'):\n",
    "    listona.append(i.string)\n",
    "indice = 0\n",
    "listona_separado_linhas = []\n",
    "while indice < len(listona):\n",
    "    lista_provisoria=[]\n",
    "    for z in range(indice,indice+25):\n",
    "        lista_provisoria.append(listona[z])\n",
    "    listona_separado_linhas.append(lista_provisoria)\n",
    "    indice += 26\n",
    "# listona_separado_linhas\n",
    "df_fundos = pd.DataFrame(listona_separado_linhas, columns =['Código do fundo', 'Setor', 'Preço atual','Liquidez','Dividendo','Dividend Yield','DY 3M','DY 6M','DY 12M','DY 3M media','DY 6M media','DY 12M media','DY ANO','Variação Preço','Rentab. Período','Retab. Acum.','Patrimônio Líq.','VPA','P/VPA','DY PATR.','Varia. Patri.','Rentab. Patr.', 'Vacância Física','Vacância Financeira','Quantidade de ativos'])\n",
    "df_fundos\n",
    "\n",
    "df_fundos.to_excel(\"Lista_indicadores_fundo.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabela de indicadores fundamentalistas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context \n",
    "\n",
    "url_link = \"http://br.financas.yahoo.com/quote/SULA4.SA/key-statistics?p=SULA4.SA\" \n",
    "\n",
    "r = requests.get(url_link, headers ={'User-Agent':'Mozilla/5.0'})\n",
    "read_html_pandas_data = pd.read_html(r.text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
